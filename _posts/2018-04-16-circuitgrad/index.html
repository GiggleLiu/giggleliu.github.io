<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
   <link rel="stylesheet" href="/libs/katex/katex.min.css">
     
  
  <link rel="stylesheet" href="/css/franklin.css">
<link rel="stylesheet" href="/css/poole_hyde.css">
<!-- style adjustments -->
<style>
  html {font-size: 17px;}
  .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;}
  @media (min-width: 940px) {
    .franklin-content {width: 100%; margin-left: auto; margin-right: auto;}
  }
  @media (max-width: 768px) {
    .franklin-content {padding-left: 6%; padding-right: 6%;}
  }
</style>
<link rel="icon" href="/assets/favicon.png">

   <title>Get the gradient of a quantum circuit</title>  
</head>
<body>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1><a href="/">Jinguo LIU</a></h1>
      <p class="lead">Early to bed and early to rise, makes a man healthy, wealthy, and wise.</p>
    </div>
    <nav class="sidebar-nav">
      <a class="sidebar-nav-item " href="/">Home</a>
      <a class="sidebar-nav-item " href="/blogs/">Blogs</a>
      <a class="sidebar-nav-item " href="/code/">Code</a>
      <a class="sidebar-nav-item " href="/about/">About Me</a>
    </nav>
    <p>&copy; GiggleLiu.</p>
  </div>
</div>
<div class="content container">

<!-- Content appended here -->
<div class="franklin-content"><h3 id="the_landscape_of_a_quantum_circuit"><a href="#the_landscape_of_a_quantum_circuit" class="header-anchor">The landscape of a quantum circuit</a></h3>
<p>This section is a simplified discussion of results in Ref. 5. </p>
<p>Consider the expectation value of \(B\) on state \(\vert\psi_N\rangle = U_{N:k+1} U_k(\eta)U_{k-1:1}\vert\psi_0\rangle\) with \(U_k(\eta)=e^{-i\Xi\eta/2}\). Given \(\Xi^2 =1\), we have \(U_k(\eta) = \cos(\frac{\eta}{2})-i\sin(\frac{\eta}{2})\Xi\).</p>
\[
\begin{align*}
\langle B\rangle &= \langle \psi_k| \left[\cos\frac{\eta}{2}+i\sin\frac{\eta}{2}\Xi\right] \tilde{B}_{k+1} \left[\cos\frac{\eta}{2}-i\sin\frac{\eta}{2}\Xi\right]|\psi_k\rangle\\
&= \cos^2\frac{\eta}{2}\langle\psi_k| \tilde{B}_{k+1}|\psi_k\rangle +\sin^2\frac{\eta}{2}\langle\psi_k|\Xi \tilde{B}_{k+1}\Xi|\psi_k\rangle + i\sin\frac{\eta}{2}\cos\frac{\eta}{2}\langle\psi_k|\left[\Xi, \tilde{B}_{k+1}\right]|\psi_k\rangle\\
&=\cos^2\frac{\eta}{2}\left(\langle\psi_k|\tilde{B}_{k+1}-\Xi \tilde{B}_{k+1}\Xi|\psi_k\rangle\right)+ i\frac{\sin\eta}{2}\langle\psi_k|\left[\Xi, \tilde{B}_{k+1}\right]|\psi_k\rangle + \langle\psi_k|\Xi \tilde{B}_{k+1}\Xi|\psi_k\rangle\\
&=\frac{\cos\eta}{2}\left(\langle\psi_k|\tilde{B}_{k+1}-\Xi \tilde{B}_{k+1}\Xi|\psi_k\rangle\right)+ i\frac{\sin\eta}{2}\langle\psi_k|\left[\Xi, \tilde{B}_{k+1}\right]|\psi_k\rangle + \frac{1}{2}\langle\psi_k|\tilde{B}+\Xi \tilde{B}_{k+1}\Xi|\psi_k\rangle\\
&=\alpha\cos\eta+ \beta\sin\eta+\gamma\\
& = r\cos(\eta-\phi)+\gamma
\end{align*}
\]
<p>Here, In line 1, we used the following shorthands</p>
\[
\begin{align*}
&|\psi_{k}\rangle = U_{k:1}|\psi_0\rangle\\
&\tilde{B}_{k+1} = U_{N:k+1}^\dagger B U_{N:k+1}
\end{align*}
\]
<p>And in line 5, we have introduced</p>
\[
\begin{align*}
\alpha &= \frac{1}{2}\left(\langle\psi_k\vert\tilde{B}{k+1}-\Xi \tilde{B}{k+1}\Xi\vert\psi_k\rangle\right),\\
\beta &= i\frac{1}{2}\langle\psi_k\vert\left[\Xi, \tilde{B}{k+1}\right]\vert\psi_k\rangle,\\
\gamma &= \frac{1}{2}\langle\psi_k\vert\tilde{B}+\Xi \tilde{B}{k+1}\Xi\vert\psi_k\rangle.
\end{align*}
\]
<p>Finally, we obtained a sine function.</p>

<img src="/assets/images/diff_circuit.png" width="400">

<p>A direct proposition is</p>
\[
\frac{\partial \langle B\rangle_\eta}{\partial \eta} = \frac{1}{2}(\langle B\rangle_{\eta+\frac{\pi}{2}} - \langle B\rangle_{\eta-\frac{\pi}{2}})
\]
<h3 id="for_statistic_functional"><a href="#for_statistic_functional" class="header-anchor">For statistic functional</a></h3>
<p>Next, we describe a new class of differenciable loss which can not be written as an obserable easily, the statistic functionals, for simplicity, we consider an arbitrary statistic functional \(f(\mathbf{X})\), with a sequence of bit strings \(\mathbf{X}\equiv\{x_1,x_2,\ldots, x_r\}\) as its arguments. Let&#39;s define the following expectation of this function</p>
\[\mathbb{E}_f(\boldsymbol{\Gamma})\equiv\mathop{\mathbb{E}}\limits_{\substack{\{x_i\sim p_{\boldsymbol{\theta}+\boldsymbol{\gamma}_i}\}_{i=1}^{r}}}\left[f(\mathbf{X})\right].\]
<p>Here, \(\boldsymbol{\Gamma}=\{\boldsymbol{\gamma}_1, \boldsymbol{\gamma}_2,\ldots,\boldsymbol{\gamma}_r\}\) is the offset angles applied to circuit parameters, &#37;Its element \(\boldsymbol{\gamma}_i\) is defined in the same parameter space as \(\boldsymbol{\theta}\) that represents a shift to \(\boldsymbol{\theta}\). which means the probability distributions of generated samples is \(\{p_{\boldsymbol{\theta}+\boldsymbol{\gamma}_1}, p_{\boldsymbol{\theta}+\boldsymbol{\gamma}_2},\ldots ,p_{\boldsymbol{\theta}+\boldsymbol{\gamma}_r}\}\). Writing out the above expectation explicitly, we have</p>
\[\mathbb{E}_f(\boldsymbol{\Gamma})=\sum\limits_\mathbf{X} f(\mathbf{X})\prod\limits_i p_{\boldsymbol{\theta}+\boldsymbol{\gamma}_i}(x_i),\]
<p>where index \(i\) runs from \(1\) to \(r\). Its partial derivative with respect to \(\theta^\alpha_l\) is</p>
\[\frac{\partial \mathbb{E}_f(\boldsymbol{\Gamma})}{\partial \theta^\alpha_l}=\sum\limits_\mathbf{X} f(\mathbf{X})\sum\limits_j\frac{\partial p_{\boldsymbol{\theta}+\boldsymbol{\gamma}_j}(x_j)}{\partial\theta^\alpha_l}\prod\limits_{i\neq j} p_{\boldsymbol{\theta}+\boldsymbol{\gamma}_i}(x_i)\]
<p>Again, using the gradient of probability, we have</p>
\[
\begin{align*}
    \frac{\partial \mathbb{E}_f(\boldsymbol{\Gamma})}{\partial \theta^\alpha_l}&=\frac{1}{2}\sum\limits_{j,s=\pm}\sum\limits_\mathbf{X} f(\mathbf{X}){p_{\boldsymbol{\theta}+\boldsymbol{\gamma}_j+s\frac{\pi}{2}\mathbf{e}_l^\alpha}(x_j)}\prod\limits_{i\neq j} p_{\boldsymbol{\theta}+\boldsymbol{\gamma}_i}(x_i)\\
    &=\frac{1}{2}\sum\limits_{j,s=\pm}\mathbb{E}_f(\{\boldsymbol{\gamma}_i+s\delta_{ij}\frac{\pi}{2}\mathbf{e}_l^\alpha\}_{i=1}^{r})\end
{align*}
\]
<p>If \(f\) is symmetric, \(\mathbb{E}_f(\mathbf{0})\) becomes a V-statistic &#91;Mises &#40;1947&#41;&#93;, then the gradient can be further simplified to</p>
\[
\begin{align}
    \frac{\partial \mathbb{E}_f(\boldsymbol{\Gamma})}{\partial \theta^\alpha_l}=\frac{r}{2}\sum\limits_{s=\pm}\mathbb{E}_f\left(\{\boldsymbol{\gamma}_0+s\frac{\pi}{2}\mathbf{e}_l^\alpha,\boldsymbol{\gamma}_1,\ldots,\boldsymbol{\gamma}_r\}\right),
\end{align}
\]
<p>which contains only two terms. This result can be readily verified by calculating the gradient of MMD loss, noticing the expectation of a kernel function is a V-statistic of degree \(2\). By repeatedly applying the gradient formula, we will be able to obtain higher order gradients.</p>
<h3 id="references"><a href="#references" class="header-anchor">References</a></h3>
<ol>
<li><p>Jin-Guo Liu and Lei Wang, <a href="https://arxiv.org/abs/1804.04168">arXiv:1804.04168</a></p>
</li>
<li><p>J. Li, X. Yang, X. Peng, and C.-P. Sun, Phys. Rev. Lett. 118,</p>
</li>
</ol>
<p>150503 &#40;2017&#41;.</p>
<ol start="3">
<li><p>E. Farhi and H. Neven, arXiv:1802.06002.</p>
</li>
<li><p>K. Mitarai, M. Negoro, M. Kitagawa, and K. Fujii,</p>
</li>
</ol>
<p>arXiv:1803.00745.</p>
<ol start="5">
<li><p>Nakanishi, Ken M., Keisuke Fujii, and Synge Todo. </p>
</li>
</ol>
<p>arXiv:1903.12166 &#40;2019&#41;.</p>
<div class="page-foot">
    <div>
    <a href="https://github.com/GiggleLiu" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github: GiggleLiu</a>
    <br>
    <a href="https://twitter.com/GiggleLiu" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i> Twitter: GiggleLiu</a>
    <br>
    <a href="https://scholar.google.com/citations?user=4edw228AAAAJ" rel="nofollow noopener noreferrer"><i class="fa-google-scholar" aria-hidden="true"></i> Google Scholar: 4edw228AAAAJ</a>
    </div>
    <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> GiggleLiu. Last modified: November 20, 2022.
    Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
</div>
</div><!-- CONTENT ENDS HERE -->
    </div>  <!-- div: content container -->
    <script defer src="https://use.fontawesome.com/releases/v5.8.2/js/all.js" integrity="sha384-DJ25uNYET2XCl5ZF++U8eNxPWqcKohUUBUpKGlNLMchM7q4Wjg2CUpjHLaL8yYPH" crossorigin="anonymous"></script>
    
        <script src="/libs/katex/katex.min.js"></script>
<script src="/libs/katex/contrib/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>

    
    

  </body>

</html>
